{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/06\n"
     ]
    }
   ],
   "source": [
    "from root_numpy import root2array, tree2array\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(799.245  , 777.50684, 777.50684) (688.7374 , 685.90155, 685.90155)\n",
      " (386.379  , 365.84082, 365.84082) ... (368.45944, 369.37573, 369.37573)\n",
      " (409.72958, 417.1106 , 417.1106 ) (137.92084, 213.0208 , 213.0208 )]\n",
      "******************************************************************************\n",
      "*Tree    :Tree      : Tree                                                   *\n",
      "*Entries :  1000000 : Total =        12035518 bytes  File  Size =   10778962 *\n",
      "*        :          : Tree compression factor =   1.12                       *\n",
      "******************************************************************************\n",
      "*Br    0 :Reco      : Reco/F                                                 *\n",
      "*Entries :  1000000 : Total  Size=    4011767 bytes  File Size  =    3596983 *\n",
      "*Baskets :      126 : Basket Size=      32000 bytes  Compression=   1.11     *\n",
      "*............................................................................*\n",
      "*Br    1 :Gen       : Gen/F                                                  *\n",
      "*Entries :  1000000 : Total  Size=    4011637 bytes  File Size  =    3581915 *\n",
      "*Baskets :      126 : Basket Size=      32000 bytes  Compression=   1.12     *\n",
      "*............................................................................*\n",
      "*Br    2 :data      : data/F                                                 *\n",
      "*Entries :  1000000 : Total  Size=    4011767 bytes  File Size  =    3596983 *\n",
      "*Baskets :      126 : Basket Size=      32000 bytes  Compression=   1.11     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "rfile = ROOT.TFile(\"TreeFile.root\")\n",
    "intree = rfile.Get('Tree')\n",
    "intree.Print()\n",
    "# and convert the TTree into an array\n",
    "array = tree2array(intree,branches=[\"Gen\",\"Reco\",\"data\"])\n",
    "array.dtype.names = ('reco', \"gen\", \"data\")\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb114e7c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.16000e+02 2.15860e+04 1.46504e+05 2.43194e+05 1.78346e+05 1.14436e+05\n",
      " 8.02140e+04 6.10580e+04 4.81930e+04 3.91600e+04 3.29390e+04 2.36680e+04\n",
      " 9.20300e+03 9.60000e+02 2.30000e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb09350f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb0930b090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(array)\n",
    "\n",
    "#print(df)\n",
    "content_reco ,bin,patches = plt.hist(df['reco'], bins=15)\n",
    "plt.ylabel('# events')\n",
    "plt.xlabel(\"reco\")\n",
    "plt.show()\n",
    "\n",
    "content_gen ,bin,patches = plt.hist(df['gen'], bins=15)\n",
    "print(content_gen)\n",
    "plt.ylabel('# events')\n",
    "plt.xlabel(\"gen\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist2d(df['reco'],df['gen'], bins=10, range=[[0, 1000], [0, 1000]],norm=LogNorm())\n",
    "plt.ylabel('# events')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swieland/tools/root/lib/ROOT.py:318: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return _orig_ihook( name, *args, **kwds )\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# KERAS imports:\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "num_classes = 20\n",
    "NBins = num_classes\n",
    "epochs = 10\n",
    "#\n",
    "# Define initial function:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[777.50684 685.90155 365.84082 ... 369.37573 417.1106  213.0208 ]\n",
      "(1000000,)\n",
      "[3. 3. 1. ... 1. 2. 1.]\n",
      "[799.245   688.7374  386.379   ... 368.45944 409.72958 137.92084]\n",
      "(1000000,)\n",
      "[3. 3. 1. ... 1. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "gen=df[\"gen\"].values\n",
    "print(gen)\n",
    "print(gen.shape)\n",
    "g=np.trunc(gen/200)\n",
    "print(g)\n",
    "reco=df[\"reco\"].values\n",
    "print(reco)\n",
    "print(reco.shape)\n",
    "r=np.trunc(reco/200)\n",
    "print(r)\n",
    "data=df[\"data\"].values\n",
    "data=np.trunc(data/200)\n",
    "data = data.reshape(data.shape[0],1,1)\n",
    "gcat = keras.utils.to_categorical(g,NBins)\n",
    "from sklearn.model_selection import train_test_split\n",
    "r = r.reshape(r.shape[0],1,1)\n",
    "r_train, r_test, g_train, g_test = train_test_split(r, gcat, test_size=0.22, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareModel(nvar=1, NBins=10, kappa=8):\n",
    "    ''' Prepare KERAS-based sequential neural network with for ML unfolding. \n",
    "        Nvar defines number of inputvariables. NBins is number of truth bins. \n",
    "        kappa is an empirically tuned parameter for the intermediate layer'''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nvar,activation='linear',input_shape=(nvar,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(kappa*NBins**2,activation='relu'))\n",
    "    \n",
    "    # model.add(Dropout(0.25))\n",
    "    # model.add(Dense(2*NBins,activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(NBins,activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "model = prepareModel(1,NBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780000 samples, validate on 220000 samples\n",
      "Epoch 1/10\n",
      "780000/780000 [==============================] - 23s 29us/step - loss: 0.6056 - acc: 0.8099 - val_loss: 0.5615 - val_acc: 0.8166\n",
      "Epoch 2/10\n",
      "780000/780000 [==============================] - 22s 28us/step - loss: 0.5508 - acc: 0.8171 - val_loss: 0.5509 - val_acc: 0.8166\n",
      "Epoch 3/10\n",
      "780000/780000 [==============================] - 22s 29us/step - loss: 0.5500 - acc: 0.8171 - val_loss: 0.5506 - val_acc: 0.8166\n",
      "Epoch 4/10\n",
      "780000/780000 [==============================] - 24s 30us/step - loss: 0.5500 - acc: 0.8171 - val_loss: 0.5496 - val_acc: 0.8166\n",
      "Epoch 5/10\n",
      "780000/780000 [==============================] - 22s 29us/step - loss: 0.5495 - acc: 0.8171 - val_loss: 0.5489 - val_acc: 0.8166\n",
      "Epoch 6/10\n",
      "780000/780000 [==============================] - 22s 28us/step - loss: 0.5492 - acc: 0.8171 - val_loss: 0.5527 - val_acc: 0.8166\n",
      "Epoch 7/10\n",
      "780000/780000 [==============================] - 25s 32us/step - loss: 0.5493 - acc: 0.8171 - val_loss: 0.5510 - val_acc: 0.8166\n",
      "Epoch 8/10\n",
      "780000/780000 [==============================] - 21s 27us/step - loss: 0.5492 - acc: 0.8171 - val_loss: 0.5493 - val_acc: 0.8166\n",
      "Epoch 9/10\n",
      "780000/780000 [==============================] - 20s 26us/step - loss: 0.5492 - acc: 0.8171 - val_loss: 0.5489 - val_acc: 0.8166\n",
      "Epoch 10/10\n",
      "780000/780000 [==============================] - 21s 27us/step - loss: 0.5490 - acc: 0.8171 - val_loss: 0.5506 - val_acc: 0.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-22 23:31:34.843612: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(r_train,g_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(r_test,g_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model,if needed\n",
    "model.save(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220000/220000 [==============================] - 3s 13us/step\n",
      "[0.5505959611025724, 0.8166045454545454]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(r_test, g_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "2 2\n",
      "3 3\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "2 2\n",
      "0 0\n",
      "1 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "2 2\n",
      "0 0\n",
      "1 1\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "prob = model.predict(r_test, batch_size=128)\n",
    "classes=prob.argmax(axis=-1)\n",
    "np.set_printoptions(threshold=100000)\n",
    "for i in range(20):    \n",
    "    print(classes[i],g_test.argmax(axis=-1)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
